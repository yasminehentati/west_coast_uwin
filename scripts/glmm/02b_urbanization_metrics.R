################################################################################
################# West Coast Env Health GLMM Analysis ##########################
#################         Step 2: Covariates          ##########################
#################   Yasmine Hentati yhentati@uw.edu   ##########################
################################################################################

### NDVI calculation code adapted from T. Gallo ###
### NDVI composite dataset generated by G. Cova ### 

## packages 
library(raster)
library(sf)
library(dplyr)
library(mapview) # note that mapview is somewhat demanding, consider skipping
# mapview functions if your computer is slow  - these are just used to check 
# that shapefiles look correct 
library(rgdal)
library(raster)
library(here)
library(remotes)
library(tidycensus)
# remotes::install_github("walkerke/crsuggest") 
library(crsuggest)
library(tidyr)
library(terra)
install.packages("spatialEco")
library(spatialEco)

################################################################################
## notes on projections: we're going to use WGS84/UTM because we need to work in 
## meters for our buffers. however, the data is split across 2 zones (11N and 10N)
## so all steps will need to be done twice - once for each zone 
################################################################################
## CAMERA LOCATIONS 
## get camera points 



# load all sites
all_sites <- read.csv(here("data", "counts_cleaned.csv"), stringsAsFactors = FALSE)

# order data by Location Name 
all_sites <- all_sites[order(all_sites$Site),]
nrow(all_sites)

# split by zone

# create new column for utm zone 
data_10_WA <- all_sites %>% subset(City == "tawa")
data_10_WA$utmZone <- "10"

data_10_SF <- all_sites %>% subset(City == "oaca")
data_10_SF$utmZone <- "10"

data_LA <- all_sites %>% subset(City == "paca" | City == "lbca")
data_LA$utmZone <- "11"

# transform into UTM - WA
utm1 <- data.frame(x=data_10_WA$Long, y=data_10_WA$Lat) 
coordinates(utm1) <- ~x+y 
proj4string(utm1) <- CRS("+proj=longlat +datum=WGS84") 
utm2 <- spTransform(utm1,CRS("+init=epsg:32610"))

data_10_WA$utmEast <- utm2$x
data_10_WA$utmNorth <- utm2$y

# transform into UTM - SF
utm1 <- data.frame(x=data_10_SF$Long, y=data_10_SF$Lat) 
coordinates(utm1) <- ~x+y 
proj4string(utm1) <- CRS("+proj=longlat +datum=WGS84") 
utm2 <- spTransform(utm1,CRS("+init=epsg:32610"))

data_10_SF$utmEast <- utm2$x
data_10_SF$utmNorth <- utm2$y

# transform into UTM - LA
utm1 <- data.frame(x=data_LA$Long, y=data_LA$Lat) 
coordinates(utm1) <- ~x+y 
proj4string(utm1) <- CRS("+proj=longlat +datum=WGS84") 
utm2 <- spTransform(utm1,CRS("+init=epsg:32611"))

data_LA$utmEast <- utm2$x
data_LA$utmNorth <- utm2$y

# turn coordinates into spatial points
points_WA <- data_10_WA %>% distinct(Site, .keep_all = TRUE) %>%
  st_as_sf(coords = c("utmEast", "utmNorth"), crs = 
                     32610)
points_WA
points_SF <- st_as_sf(data_10_SF, coords = c("utmEast", "utmNorth"), crs = 
                        32610)

points_LA <- st_as_sf(data_LA, coords = c("utmEast", "utmNorth"), crs = 
                        32611)


# check that the points look ok
# mapview(points_WA)
# mapview(points_SF)
# mapview(points_LA)


# keep only 1 unique site row for each 

points_WA <- points_WA %>% distinct(Site, .keep_all = TRUE)
points_WA$Site

points_SF <- points_SF %>% distinct(Site, .keep_all = TRUE)
points_SF

points_LA <- points_LA %>% distinct(Site, .keep_all = TRUE)
points_LA

################################################################################
## INCOME DATA
## median household income data from American Community Survey

Sys.getenv("CENSUS_API_KEY")
# load census API key
# census_api_key("e649b78a1d98fe7e1c9ff7039840781976777eb6",
           #    install = TRUE)
# readRenviron("~/.Renviron")

# load in ACS variables  from 2019 
v17 <- load_variables(2019, "acs5", cache = TRUE)


# load in shapefile of subdivisions  
# with median household income as variable of interest

# for washington 
tractincomeWA <- get_acs(state = "WA", 
                         geography = "tract", 
                         variables = c(medincome="B19013_001"), geometry = TRUE)

# for california
tractincomeCA <- get_acs(state = "CA", 
                         geography = "tract", 
                         variables = c(medincome="B19013_001"), geometry = TRUE)

# save whole state to a shapefile - currently not needed so will leave as comment
# st_write(tractincomeWA, "WA_med_income.shp", append = FALSE)
# st_write(tractincomeCA, "CA_med_income.shp", append = FALSE)

# determine coordinate system
suggest_top_crs(tractincomeWA) # 32148 is projected CRS 

# cut out everything except king and pierce county from our WA shp 
# specify dplyr because rgdal also has filter fxn 
# do this using the GEOID codes for each county 

tractsKP <- tractincomeWA %>% dplyr::filter(substr(GEOID, 1, 5) 
                                            %in% c("53033", "53053"))

# mapview(tractsKP) # looks good

# write king and pierce county shapefiles 

# st_write(tractsKP, here("data", "income_maps", "seatac_med_income.shp"),
    #      append = FALSE)

# crop to actual study area 
tractsKP <- st_transform(tractsKP, crs=4326)
tractsKP_crop <- st_crop(tractsKP, c(xmin= -121.7, ymin = 46.7, xmax = -122.8, ymax = 47.8))

# write shapefiles for cropped area 
# st_write(tractsKP_crop, here("data", "income_maps", "seatac_urban_med_income.shp"),
     #     append = FALSE)


# do the same for the bay area
# counties: napa marin solano contra costa 
# alameda san fransisco san mateo santa clara 

tractsSF <- tractincomeCA %>% dplyr::filter(substr(GEOID, 1, 5) 
                                            %in% c("06055", "06041", 
                                                   "06095", "06013",
                                                   "06001", "06075",
                                                   "06081", "06085"))

# mapview(tractsSF)

# write SF bay area  shapefiles 
# st_write(tractsSF, here("data", "income_maps", "sf_bay_med_income.shp"),
         # append = FALSE)

# do the same for LA
# just LA county 
tractsLA <- tractincomeCA %>% dplyr::filter(substr(GEOID, 1, 5) 
                                            %in% c("06037"))

# mapview(tractsLA)
# write LA area shapefiles 
# st_write(tractsLA, here("data", "income_maps", "la_county_med_income.shp"),
        #  append = FALSE)


################################################################################
## HOUSING DENSITY DATA 
## read in housing density  data - starting with WA 

wa_housing <- st_read(here("data", "housing_maps", 
        "wa_blk10_Census_change_1990_2010_PLA2.shp"))

# filter to only king and pierce county
wa_housing <- wa_housing %>% dplyr::filter(substr(BLK10, 1, 5) 
                                            %in% c("53033", "53053"))

# we only need 2010 housing data - select relevant info

colnames(wa_housing)
wa_housing <- wa_housing %>% dplyr::select(BLK10, WATER10, POP10, 
                                           HU10, HUDEN10, HHUDEN10,
                                           PUBFLAG:geometry)
colnames(wa_housing)

# crop to actual study area 
sf_use_s2(FALSE)
wa_housing <- st_transform(wa_housing, crs=4326)
wa_housing <- st_crop(wa_housing, c(xmin= -121.7, ymin = 46.7, xmax = -122.8, ymax = 47.8))

# mapview(wa_housing)

# st_write(wa_housing, here("data", "housing_maps", "wa_urban_huden_2010.shp"),
      #    append = FALSE)

# do the same with SF 

ca_housing <- st_read(here("data", "housing_maps", 
                           "ca_blk10_Census_change_1990_2010_PLA2.shp"))

# filter to only bay area counties
sf_housing <- ca_housing %>% dplyr::filter(substr(BLK10, 1, 5) 
                                           %in% c("06055", "06041", 
                                                  "06095", "06013",
                                                  "06001", "06075",
                                                  "06081", "06085"))

# we only need 2010 housing data - select relevant info

colnames(sf_housing)
sf_housing <- sf_housing %>% dplyr::select(BLK10, WATER10, POP10, 
                                           HU10, HUDEN10, HHUDEN10,
                                           PUBFLAG:geometry)
colnames(sf_housing)


# st_write(sf_housing, here("data", "housing_maps", "sf_urban_huden_2010.shp"),
     #     append = FALSE)



# do the same with LA 

# filter to only LA cty
la_housing <- ca_housing %>% dplyr::filter(substr(BLK10, 1, 5) 
                                           %in% c("06037"))

# we only need 2010 housing data - select relevant info

colnames(la_housing)
la_housing <- la_housing %>% dplyr::select(BLK10, WATER10, POP10, 
                                           HU10, HUDEN10, HHUDEN10,
                                           PUBFLAG:geometry)
colnames(la_housing)

# st_write(la_housing, here("data", "housing_maps", "la_urban_huden_2010.shp"),
#          append = FALSE)


################################################################################
## VEGETATION DATA 

# load LandSat NDVI raster from GRC GEE code 

ndvi_kp <- raster(here("data", "NDVI_data", "NDVI2020-TAWA-30-3857.TIF"))

suggest_top_crs(ndvi_kp)
ndvi_kp <- projectRaster(ndvi_kp, crs = "EPSG:6599")

# reproject points to raster crs 
points_WA <- st_transform(points_WA, crs = st_crs(ndvi_kp))
points_WA
# extract the proportion of the buffer that has an NDVI greater than 0.2 (vegetation cover)
# this returns a list, so we can use lapply to calculate the proportion for each site
ndvi_extract <- raster::extract(ndvi_kp, points_WA, buffer = 1000)

# calculate the proportion of a site that is covered in vegetation
prop_ndvi_greater0.2 <- lapply(ndvi_extract, function (x){
  # turn values greater than 0.2 to 1 (these are cells that are covered in vegetation)
  x[which(x > 0.2)] <- 1
  # turn values less than 0.2 to 0 (these are cells that are not vegetation)
  x[which(x <= 0.2)] <- 0
  # proportion of cells that are vegetation
  sum(x, na.rm = TRUE)/length(x) })


# turn list into a vector
prop_veg <- do.call(c, prop_ndvi_greater0.2)
prop_veg

points_WA$prop_veg <- prop_veg

# for SF
# currently this doesn't cover the whole bay area - will need to update 

ndvi_sf <- raster(here("data", "NDVI_data", "NDVI2020_OACA-30-3857.TIF"))
suggest_top_crs(ndvi_sf)
ndvi_sf <- projectRaster(ndvi_sf, crs = "EPSG:7132")

# reproject points to raster crs 
points_SF <- st_transform(points_SF, crs = st_crs(ndvi_sf))
points_SF

# extract the proportion of the buffer that has an NDVI greater than 0.2 (vegetation cover)
# this returns a list, so we can use lapply to calculate the proportion for each site
ndvi_extract <- raster::extract(ndvi_sf, points_SF, buffer = 1000)

# calculate the proportion of a site that is covered in vegetation
prop_ndvi_greater0.2 <- lapply(ndvi_extract, function (x){
  # turn values greater than 0.2 to 1 (these are cells that are covered in vegetation)
  x[which(x > 0.2)] <- 1
  # turn values less than 0.2 to 0 (these are cells that are not vegetation)
  x[which(x <= 0.2)] <- 0
  # proportion of cells that are vegetation
  sum(x, na.rm = TRUE)/length(x) })


# turn list into a vector
prop_veg <- do.call(c, prop_ndvi_greater0.2)
prop_veg

points_SF$prop_veg <- prop_veg

# for LA 

# read in NDVI
ndvi_la <- raster(here("data", "NDVI_data", "NDVI2020_LACA-30-3857.TIF"))
suggest_top_crs(ndvi_la)
ndvi_la <- projectRaster(ndvi_la, crs = "EPSG:26799")

# reproject points to raster crs 
points_LA <- st_transform(points_LA, crs = st_crs(ndvi_la))
st_crs(points_LA)
# extract the proportion of the buffer that has an NDVI greater than 0.2 (vegetation cover)
# this returns a list, so we can use lapply to calculate the proportion for each site
ndvi_extract <- raster::extract(ndvi_la, points_LA, buffer = 1000)

# calculate the proportion of a site that is covered in vegetation
prop_ndvi_greater0.2 <- lapply(ndvi_extract, function (x){
  # turn values greater than 0.2 to 1 (these are cells that are covered in vegetation)
  x[which(x > 0.2)] <- 1
  # turn values less than 0.2 to 0 (these are cells that are not vegetation)
  x[which(x <= 0.2)] <- 0
  # proportion of cells that are vegetation
  sum(x, na.rm = TRUE)/length(x) })


# turn list into a vector
prop_veg <- do.call(c, prop_ndvi_greater0.2)
prop_veg

points_LA$prop_veg <- prop_veg

################################################################################
## ENVIRONMENTAL HEALTH DATA 
# obtained from calenviroscreen and washington environmental health disparities map

## starting with calenviroscreen
calenv <- read.csv(here("data", "calenviroscreen_v4.csv"))

head(calenv)

#get only our counties of interest 
calenv <- calenv %>% dplyr::filter(substr(Census.Tract, 1, 4) 
                                         %in% c("6055", "6041", 
                                                "6095", "6013",
                                                "6001", "6075",
                                                "6081", "6085",
                                                "6037"))
# remove variables we don't care about
calenv <- calenv %>% dplyr::select(Census.Tract, CES.4.0.Percentile)

# convert into rankings to match washington data

# divide percentile by 10
calenv <- calenv %>%  
  mutate(NewPercentile = CES.4.0.Percentile / 10)

# drop NAs
calenv <- drop_na(calenv)

# round to ranking - we'll do the same as WA EHD and round at 0.5

half_ceil <- function(x){
  whole = ceiling(x)
  if(x >= whole - .5){
    return(whole)
  } else
  return(whole - 1)
}

calenv$CESrank <- sapply(calenv$NewPercentile, half_ceil)

# remove everything except rankings and tract name 
calenv <- calenv %>% dplyr::select(Census.Tract, CESrank)
calenv

# now with wa
waenv <- read.csv(here("data", "wa_envhealthdisp_v2.csv"))

#get only our counties of interest 
waenv <- waenv %>% dplyr::filter(substr(State.FIPS.Code, 1, 5) 
                                   %in% c("53053", "53033"))


# rename col names to match
colnames(waenv) <- c("GEOID", "Rank")
colnames(calenv) <- c("GEOID", "Rank")

# add leading 0s to california data
library(bit64)

calenv$GEOID <- sprintf("%011s", calenv$GEOID)

# this is now characters, so change waenv to match
waenv$GEOID <- as.character(waenv$GEOID)

# bind together
env_data <- rbind(waenv,calenv)
env_data$GEOID




################################################################################

################################################################################
## impervious surface calculation 

# load impervious cover raster map
imp_map <- raster(here("data", "NCLD_imp", 
                       "nlcd_2019_impervious_descriptor_l48_20210604.img"))

# again reproject  points to match raster
# these are just the points not the buffers
points_WA <- st_transform(points_WA, st_crs(imp_map))

# extract the mean impervious cover around each point using 500 m radius buffer
imp <- raster::extract(imp_map, points_WA, fun=mean, buffer= 1000, df=TRUE)
imp

points_WA$imp_surf <- imp$Class_Names

# for SF 
points_SF <- st_transform(points_SF, st_crs(imp_map))

# extract the mean impervious cover around each point using 500 m radius buffer
imp <- raster::extract(imp_map, points_SF, fun=mean, buffer= 1000, df=TRUE)
imp

points_SF$imp_surf <- imp$Class_Names

# for LA 
points_LA <- st_transform(points_LA, st_crs(imp_map))

# extract the mean impervious cover around each point using 500 m radius buffer
imp <- raster::extract(imp_map, points_LA, fun=mean, buffer= 1000, df=TRUE)
points_LA$imp_surf <- imp$Class_Names

################################################################################
# additional calculations

# merge the env health data to polygons

env_LA <- merge(tractsLA, env_data, by.x = "GEOID",
                      by.y = "GEOID")

env_WA <- merge(tractsKP, env_data, by.x = "GEOID",
                by.y = "GEOID")

env_SF <- merge(tractsSF, env_data, by.x = "GEOID",
                by.y = "GEOID")

env_data

# remove empty geometries first for WA 
env_WA <- env_WA[!st_is_empty(env_WA),]

# reproject to match NDVI rasters
env_LA <- st_transform(env_LA, st_crs(ndvi_la))
env_WA <- st_transform(env_WA, st_crs(ndvi_kp))
env_SF <- st_transform(env_SF, st_crs(ndvi_sf))

# rasterize so we can get buffers for the points 
wa_env_rast <- rasterize(env_WA, ndvi_kp,
                          field = "Rank")

sf_env_rast <- rasterize(env_SF, ndvi_sf,
                         field = "Rank")

la_env_rast <- rasterize(env_LA, ndvi_la,
                         field = "Rank")


# reproject points to match 
points_LA <- st_transform(points_LA, st_crs(la_env_rast))
points_WA <- st_transform(points_WA, st_crs(wa_env_rast))
points_SF <- st_transform(points_SF, st_crs(sf_env_rast))

# extract buffers
wa_env_values <- raster::extract(wa_env_rast, points_WA, fun=mean, buffer= 1000, df=TRUE)

sf_env_values <- raster::extract(sf_env_rast, points_SF, fun=mean, buffer= 1000, df=TRUE)

la_env_values <- raster::extract(la_env_rast, points_LA, fun=mean, buffer= 1000, df=TRUE)


points_WA$rank_buff <- wa_env_values$layer
points_SF$rank_buff <- sf_env_values$layer
points_LA$rank_buff <- la_env_values$layer

# write csv to save all covs so far 
data_WA <- st_drop_geometry(points_WA)

################################################################################

################################################################################

# housing density buffer - WA
#  transform to shapefile - need a masking raster, we'll use NDVI 
# transform to same proj
wa_housing <- st_transform(wa_housing, st_crs(ndvi_kp))
# change to raster 
wa_hous_rast <- rasterize(wa_housing, ndvi_kp,
                          field = "HUDEN10")

# transform points to same proj as raster
points_WA<- st_transform(points_WA, st_crs(wa_hous_rast))

# calculate housing density average w/ 1000m buffer
hu_den <- raster::extract(wa_hous_rast, points_WA, fun=mean, buffer= 1000, df=TRUE)
hu_den

points_WA$huden2010 <- hu_den$layer

# housing density buffer - SF
#  transform to shapefile - need a masking raster, we'll use NDVI 
# transform to same proj
sf_housing <- st_transform(sf_housing, st_crs(ndvi_sf))
# change to raster 
sf_hous_rast <- rasterize(sf_housing, ndvi_sf,
                          field = "HUDEN10")

# transform points to same proj as raster
points_SF<- st_transform(points_SF, st_crs(sf_hous_rast))

# calculate housing density average w/ 1000m buffer
hu_den <- raster::extract(sf_hous_rast, points_SF, fun=mean, buffer= 1000, df=TRUE)
hu_den

points_SF$huden2010 <- hu_den$layer

# housing density buffer - LA 
# for LA, we'll need to clip the shp (there are island in LA count that 
# are cut out of our raster)

# first we'll make a polygon out of our raster extent to create a boundary,
# then clip the housing density polygon
library(rgeos)


ndvi_poly <- as.polygons(ext(ndvi_la), crs = "EPSG:26799")
ndvi_poly <- st_as_sf(ndvi_poly)

# transform to same proj
la_housing <- st_transform(la_housing, st_crs(ndvi_poly))

la_hous_crop <- st_intersection(la_housing, ndvi_poly)
mapview(la_hous_crop)

#  transform to shapefile - need a masking raster 

# change to raster 
la_hous_rast <- rasterize(la_hous_crop, ndvi_la,
                          field = "HUDEN10")

# transform points to same proj as raster
points_LA<- st_transform(points_LA, st_crs(la_hous_rast))

# calculate housing density average w/ 1000m buffer
hu_den <- raster::extract(la_hous_rast, points_LA, fun=mean, buffer= 1000, df=TRUE)
hu_den

points_LA$huden2010 <- hu_den$layer

################################################################################
# income buffer - WA
#  transform to shapefile - need a masking raster, we'll use NDVI 
# transform to same proj
wa_income <- st_transform(tractsKP, st_crs(ndvi_kp))
# change to raster 
wa_inc_rast <- rasterize(wa_income, ndvi_kp,
                          field = "med_inc")

# transform points to same proj as raster
points_WA<- st_transform(points_WA, st_crs(wa_inc_rast))

# calculate housing density average w/ 1000m buffer
med_inc <- raster::extract(wa_inc_rast, points_WA, fun=mean, buffer= 1000, df=TRUE)
med_inc

points_WA$med_inc <- med_inc$layer

# income buffer - SF
#  transform to shapefile - need a masking raster, we'll use NDVI 
# transform to same proj
sf_income <- st_transform(tractsSF, st_crs(ndvi_sf))
# change to raster 
sf_inc_rast <- rasterize(sf_income, ndvi_sf,
                         field = "med_inc")

# transform points to same proj as raster
points_SF<- st_transform(points_SF, st_crs(sf_inc_rast))

# calculate housing density average w/ 1000m buffer
med_inc <- raster::extract(sf_inc_rast, points_SF, fun=mean, buffer= 1000, df=TRUE)
med_inc

points_SF$med_inc <- med_inc$layer

# income buffer - LA 
#  transform to shapefile - need a masking raster, we'll use NDVI 
# transform to same proj
la_income <- st_transform(tractsLA, st_crs(ndvi_la))
# change to raster 
la_inc_rast <- rasterize(la_income, ndvi_la,
                         field = "med_inc")

# transform points to same proj as raster
points_LA<- st_transform(points_LA, st_crs(la_inc_rast))

# calculate housing density average w/ 1000m buffer
med_inc <- raster::extract(la_inc_rast, points_LA, fun=mean, buffer= 1000, df=TRUE)
med_inc

points_LA$med_inc <- med_inc$layer

# merge WA/SF/LA points 
suggest_top_crs(points_LA)

env_data

# first get everything into the same projection 
points_WA <- st_transform(tractsKP, st_crs(ndvi_kp))
wa_income <- st_transform(tractsKP, st_crs(ndvi_kp))
wa_income <- st_transform(tractsKP, st_crs(ndvi_kp))

glimpse(points_WA)

# env health rank buffer

# merge all metadata with count data 

################################################################################
# pca 


urb_pca <- prcomp(counts_df[,c(1:7,10,11)], center = TRUE,scale. = TRUE)

summary(mtcars.pca)


################################################################################
# write csv to save all covs 
# don't need geometries
data_WA <- st_drop_geometry(points_WA)
data_SF <- st_drop_geometry(points_SF)
data_LA <- st_drop_geometry(points_LA)

write_csv(data_WA, here("data", "WA_counts_covs_10-20-22.csv"))
write_csv(data_SF, here("data", "SF_counts_covs_10-20-22.csv"))
write_csv(data_LA, here("data", "LA_counts_covs_10-20-22.csv"))
