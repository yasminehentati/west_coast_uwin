################################################################################
################# West Coast Env Health GLMM Analysis ##########################
#################         Step 2: Covariates          ##########################
#################   Yasmine Hentati yhentati@uw.edu   ##########################
################################################################################

### NDVI calculation code adapted from T. Gallo ###
### NDVI composite dataset generated by G. Cova ### 

## packages 
library(raster)
library(sf)
library(dplyr)
library(mapview) # note that mapview is somewhat demanding, consider skipping
# mapview functions if your computer is slow  - these are just used to check 
# that shapefiles look correct 
library(rgdal)
library(raster)
library(here)
library(remotes)
library(tidycensus)
# remotes::install_github("walkerke/crsuggest") 
library(crsuggest)
library(tidyr)


################################################################################
## notes on projections: we're going to use WGS84/UTM because we need to work in 
## meters for our buffers. however, the data is split across 2 zones (11N and 10N)
## so all steps will need to be done twice - once for 
################################################################################
## CAMERA LOCATIONS 
## get camera points 



# load all sites
all_sites <- read.csv(here("data", "count_data_fall20-sum21.csv"), stringsAsFactors = FALSE)

# order data by Location Name 
all_sites <- all_sites[order(all_sites$locationID),]
nrow(all_sites)

# subset by UTM zone 
data_10_WA <- all_sites %>% subset(utmZone == "10" & city == "tawa")

data_10_SF <- all_sites %>% subset(utmZone == "10" & city == "oaca")

data_LA <- all_sites %>% subset(utmZone == "11")



# turn coordinates into spatial points
points_WA <- st_as_sf(data_10_WA, coords = c("utmEast", "utmNorth"), crs = 
                     32610)

points_SF <- st_as_sf(data_10_SF, coords = c("utmEast", "utmNorth"), crs = 
                        32610)

points_LA <- st_as_sf(data_LA, coords = c("utmEast", "utmNorth"), crs = 
                        32611)



# check that the points look ok
mapview(points_WA)
mapview(points_SF)
mapview(points_LA)


################################################################################
## INCOME DATA
## median household income data from American Community Survey

Sys.getenv("CENSUS_API_KEY")
# load census API key
census_api_key("e649b78a1d98fe7e1c9ff7039840781976777eb6",
               install = TRUE)

# load in ACS variables  from 2019 
v17 <- load_variables(2019, "acs5", cache = TRUE)


# load in shapefile of subdivisions  
# with median household income as variable of interest

# for washington 
tractincomeWA <- get_acs(state = "WA", 
                         geography = "tract", 
                         variables = c(medincome="B19013_001"), geometry = TRUE)

# for california
tractincomeCA <- get_acs(state = "CA", 
                         geography = "tract", 
                         variables = c(medincome="B19013_001"), geometry = TRUE)

# save whole state to a shapefile - currently not needed so will leave as comment
# st_write(tractincomeWA, "WA_med_income.shp")
# st_write(tractincomeCA, "CA_med_income.shp")

# determine coordinate system
suggest_top_crs(tractincomeWA) # 32148 is projected CRS 

# cut out everything except king and pierce county from our WA shp 
# specify dplyr because rgdal also has filter fxn 
# do this using the GEOID codes for each county 

tractsKP <- tractincomeWA %>% dplyr::filter(substr(GEOID, 1, 5) 
                                            %in% c("53033", "53053"))

mapview(tractsKP) # looks good

# write king and pierce county shapefiles 
st_write(tractsKP, here("data", "income_maps", "seatac_med_income.shp"))

# crop to actual study area 
tractsKP <- st_transform(tractsKP, crs=4326)
tractsKP_crop <- st_crop(tractsKP, c(xmin= -121.7, ymin = 46.7, xmax = -122.8, ymax = 47.8))

# write shapefiles for cropped area 
st_write(tractsKP_crop, here("data", "income_maps", "seatac_urban_med_income.shp"))


# do the same for the bay area
# counties: napa marin solano contra costa 
# alameda san fransisco san mateo santa clara 

tractsSF <- tractincomeCA %>% dplyr::filter(substr(GEOID, 1, 5) 
                                            %in% c("06055", "06041", 
                                                   "06095", "06013",
                                                   "06001", "06075",
                                                   "06081", "06085"))

mapview(tractsSF)

# write SF bay area  shapefiles 
st_write(tractsSF, here("data", "income_maps", "sf_bay_med_income.shp"))

# do the same for LA
# just LA county 
tractsLA <- tractincomeCA %>% dplyr::filter(substr(GEOID, 1, 5) 
                                            %in% c("06037"))

mapview(tractsLA)
# write LA area shapefiles 
st_write(tractsLA, here("data", "income_maps", "la_county_med_income.shp"))



################################################################################
## HOUSING DENSITY DATA 
## read in housing density  data - starting with WA 

wa_housing <- st_read(here("data", "housing_maps", 
        "wa_blk10_Census_change_1990_2010_PLA2.shp"))

# filter to only king and pierce county
wa_housing <- wa_housing %>% dplyr::filter(substr(BLK10, 1, 5) 
                                            %in% c("53033", "53053"))

# we only need 2010 housing data - select relevant info

colnames(wa_housing)
wa_housing <- wa_housing %>% dplyr::select(BLK10, WATER10, POP10, 
                                           HU10, HUDEN10, HHUDEN10,
                                           PUBFLAG:geometry)
colnames(wa_housing)

# crop to actual study area 
sf_use_s2(FALSE)
wa_housing <- st_transform(wa_housing, crs=4326)
wa_housing <- st_crop(wa_housing, c(xmin= -121.7, ymin = 46.7, xmax = -122.8, ymax = 47.8))

mapview(wa_housing)



# do the same with SF 

ca_housing <- st_read(here("data", "housing_maps", 
                           "ca_blk10_Census_change_1990_2010_PLA2.shp"))

# filter to only king and pierce county
wa_housing <- wa_housing %>% dplyr::filter(substr(BLK10, 1, 5) 
                                           %in% c("53033", "53053"))

# we only need 2010 housing data - select relevant info

colnames(wa_housing)
wa_housing <- wa_housing %>% dplyr::select(BLK10, WATER10, POP10, 
                                           HU10, HUDEN10, HHUDEN10,
                                           PUBFLAG:geometry)
colnames(wa_housing)
mapview(wa_housing)

st_write(wa_housing, here("data", "housing_maps", "kp_urban_huden_2010.shp"))


################################################################################
## VEGETATION DATA 

# load LandSat NDVI raster from GRC GEE code 

ndvi_kp <- raster(here("data", "NDVI_data", "NDVI2020_KP_urban.TIF"))


# reproject points to raster crs 
points_WA <- st_transform(points_WA, crs = st_crs(ndvi_kp))

# extract the proportion of the buffer that has an NDVI greater than 0.2 (vegetation cover)
# this returns a list, so we can use lapply to calculate the proportion for each site
ndvi_extract <- raster::extract(ndvi_kp, points_WA, buffer = 1500)

# calculate the proportion of a site that is covered in vegetation
prop_ndvi_greater0.2 <- lapply(ndvi_extract, function (x){
  # turn values greater than 0.2 to 1 (these are cells that are covered in vegetation)
  x[which(x > 0.2)] <- 1
  # turn values less than 0.2 to 0 (these are cells that are not vegetation)
  x[which(x <= 0.2)] <- 0
  # proportion of cells that are vegetation
  sum(x, na.rm = TRUE)/length(x) })


# turn list into a vector
prop_veg <- do.call(c, prop_ndvi_greater0.2)
prop_veg



# extract the proportion of the buffer that has an NDVI greater than 0.2 (vegetation cover)
# this returns a list, so we can use lapply to calculate the proportion for each site
ndvi_extract <- raster::extract(ndvi_kp_10, points_10, buffer = 1000)

?extract
# calculate the proportion of a site that is covered in vegetation
prop_ndvi_greater0.2 <- lapply(ndvi_extract, function (x){
  # turn values greater than 0.2 to 1 (these are cells that are covered in vegetation)
  x[which(x > 0.2)] <- 1
  # turn values less than 0.2 to 0 (these are cells that are not vegetation)
  x[which(x <= 0.2)] <- 0
  # proportion of cells that are vegetation
  sum(x, na.rm = TRUE)/length(x) })


# turn list into a vector
prop_veg <- do.call(c, prop_ndvi_greater0.2)

prop_veg


# for LA 

# read in NDVI
ndvi_la <- raster(here("data", "NDVI_data", "NDVI2020_LA_3857.TIF"))

# reproject points to raster crs 
points_la <- st_transform(points_la, crs = st_crs(ndvi_la))

# extract the proportion of the buffer that has an NDVI greater than 0.2 (vegetation cover)
# this returns a list, so we can use lapply to calculate the proportion for each site
ndvi_extract <- raster::extract(ndvi_la, points_LA, buffer = 1000)

# calculate the proportion of a site that is covered in vegetation
prop_ndvi_greater0.2 <- lapply(ndvi_extract, function (x){
  # turn values greater than 0.2 to 1 (these are cells that are covered in vegetation)
  x[which(x > 0.2)] <- 1
  # turn values less than 0.2 to 0 (these are cells that are not vegetation)
  x[which(x <= 0.2)] <- 0
  # proportion of cells that are vegetation
  sum(x, na.rm = TRUE)/length(x) })


# turn list into a vector
prop_veg <- do.call(c, prop_ndvi_greater0.2)
prop_veg

################################################################################
## ENVIRONMENTAL HEALTH DATA 
# obtained from calenviroscreen and washington environmental health disparities map

## starting with calenviroscreen
calenv <- read.csv(here("data", "calenviroscreen_v4.csv"))

head(calenv)

#get only our counties of interest 
calenv <- calenv %>% dplyr::filter(substr(Census.Tract, 1, 4) 
                                         %in% c("6055", "6041", 
                                                "6095", "6013",
                                                "6001", "6075",
                                                "6081", "6085",
                                                "6037"))
# remove variables we don't care about
calenv <- calenv %>% dplyr::select(Census.Tract, CES.4.0.Percentile)

# convert into rankings to match washington data

# divide percentile by 10
calenv <- calenv %>%  
  mutate(NewPercentile = CES.4.0.Percentile / 10)

# drop NAs
calenv <- drop_na(calenv)

# round to ranking - we'll do the same as WA EHD and round at 0.5

half_ceil <- function(x){
  whole = ceiling(x)
  if(x >= whole - .5){
    return(whole)
  } else
  return(whole - 1)
}

calenv$CESrank <- sapply(calenv$NewPercentile, half_ceil)

# remove everything except rankings and tract name 
calenv <- calenv %>% dplyr::select(Census.Tract, CESrank)
calenv

# now with wa
waenv <- read.csv(here("data", "wa_envhealthdisp_v2.csv"))

#get only our counties of interest 
waenv <- waenv %>% dplyr::filter(substr(State.FIPS.Code, 1, 5) 
                                   %in% c("53053", "53033"))


# rename col names to match
colnames(waenv) <- c("GEOID", "Rank")
colnames(calenv) <- c("GEOID", "Rank")

# bind together
env_data <- rbind(waenv,calenv)

################################################################################
# merging everything 